{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "toc: true\n",
    "comments: true\n",
    "layout: post\n",
    "title: Computing Bias\n",
    "courses: { compsci: {week: 16} }\n",
    "type: hacks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>Introduction to Computing Bias</mark>\n",
    "A brief introduction to computing biases is that human biases are usually incorporated into algorithms or data. If this is confusing to understand, here is one example. When you are browsing Netflix and look at the different categories, you see that typically there are a bunch of Netflix exclusives being displayed more than non-exclusives. This is a form of computing bias as this would benefit Netflix, as the movie or show will never leave Netflix. So, if you get hooked on that show, then you will inevitably keep paying the Netflix subscription."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>Explicit Data vs Implicit Data</mark>\n",
    "Many software apps such as Netflix mentioned previous collect a lot of data. There are two types of data that apps collect and they are Explicit and Implicit.\n",
    "\n",
    "### <mark>Explicit</mark>:\n",
    "- Examples:\n",
    "    - Name\n",
    "    - Adress\n",
    "### <mark>Implicit</mark>:\n",
    "- Examples(Netflix):\n",
    "    - What you watch\n",
    "    - When you watched\n",
    "    - Engagement(Watch Retention)\n",
    "    - Types of movies or shows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"ADD8E6\">Popcorn Hack 1</font>\n",
    "Name a software app you know about and name some explicit and some implicit data that they collect from you the user.\n",
    "\n",
    "Answer: Spotify, explicit: billing address implicit: type of music you like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>Loan Company Example</mark>\n",
    "Another bias can be observed in trends. In the context of an app that collects information for loan officers to help them decide who the best candidate is to give a loan to, trends, for example, could show that a certain age group is comprised of better candidates for a loan. This bias is based on trends and data, and it could be beneficial to the loan officers, preventing them from losing money on loans and avoiding complications with the loanee. However, this could be harmful to the candidate applying for the loan because they might be turned away simply because they don't qualify within a certain age or race bracket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example #2\n",
    "- <mark>Movies</mark>\n",
    "    - A movie such as Dispicable Me has more of a demographic for younger people. Even though this is a bias is is beneficial because it is content that is specific to someones wants.\n",
    "    - Movies such as Star Wars are more geared toward older poeple as their target audence in contrary to a cartoon.\n",
    "- <mark>Video Games</mark>\n",
    "    - Casual Audience: These games are has a bias towards an audience that want to play casually\n",
    "        - Candy Crush\n",
    "        - Minecraft\n",
    "    - Sweaty Games: These have more of a bias for people that want to get better and play competitively\n",
    "        - Counter Strike\n",
    "        - Call of Duty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"ADD8E6\">Popcorn Hack 2</font>\n",
    "Give an example of a movie, show, or video game or even a certain softare that has a certain bias and what who the bias is towards\n",
    "\n",
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>Mitigating Bias in Algorithms</mark>\n",
    "\n",
    "To address  human biases, programmers must work towards minimizing bias in algorithms used for computing innovations. Software should aim for neutrality, considering all perspectives and actively rejecting inherent human biases.\n",
    "\n",
    "Key considerations during program development:\n",
    "\n",
    "- Identify potential sources of bias.\n",
    "- Assess whether your program is amplifying or intentionally excluding certain elements.\n",
    "- Solicit feedback from a diverse and widespread group of individuals.\n",
    "- Contemplate how people who differ from you might utilize your developments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions to ask About Bias\n",
    "- In the example of the Loan Company the bias was unintentional but could be potentially excluding fit candidates. In the example of Netflix, the bias of adding exclusives in the front of categories is intentianal but not harmful for anyone. This leads to some questions to ask if you encounter bias in a software.\n",
    "\n",
    "- <mark>Questions</mark>:\n",
    "    - Is it enhancing or intentionally excluding?\n",
    "    - Is the bias intensionally harmful or hateful?\n",
    "    - Are you receiving feedback from a wide variety of people?\n",
    "\n",
    "Using these questions, software developers are able to reduce harmful bias in algorithms and data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Hacks:\n",
    "The implementation of a predictive policing algorithm in a city has raised concerns regarding potential biases,leading to disporotionate targeting of specific neighborhoods. This over-policing could result in civil rights violation. Your task is to propose a solution to mitigate this bias and explain the method you'd use to remove computing bias. Make a full paragraph that is at least 4 sentences\n",
    "\n",
    "To make sure the predictive policing is fair, we should regularly check it with a diverse group of people. It's important to listen to the community, hear what they think, and involve them in the process. Training police officers on how the system works and potential issues is also very important. By working together, getting feedback, and talking openly, we can make the system fairer for everyone üëçüëçüëç."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code can check if you are a biased person or not\n",
      "You are bias. The code doesn't lie\n"
     ]
    }
   ],
   "source": [
    "print(\"This code can check if you are a biased person or not\")\n",
    "bias = input(\"Are you a biased person? Y/N \")\n",
    "if bias == \"Y\" or \"y\":\n",
    "    print(\"You are bias. The code doesn't lie\")\n",
    "elif bias == \"N\" or \"n\":\n",
    "    print(\"You are not biased, but are tou truthful...\")\n",
    "else:\n",
    "    print(\"Can you follow simple directions?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
